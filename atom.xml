<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[Nexys Technology]]></title>
    <link href="http://nexys-technology.github.io/atom.xml" rel="self"/>
    <link href="http://nexys-technology.github.io/"/>
    <updated>2015-08-15T10:06:15+02:00</updated>
    <id>http://nexys-technology.github.io/</id>
    <author>
        <name><![CDATA[Nexys Consulting]]></name>
        
    </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[Docker, Kafka, Storm et Hadoop HDFS 2éme partie]]></title>
        <link href="http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-2/"/>
        <updated>2015-08-13T00:00:00+02:00</updated>
        <id>http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-2</id>
        <content type="html"><![CDATA[<p>Dans cette partie nous allons déployer les containers dockers pour Kafka, Storm
et Hadoop avec l’aide de docker-compose.</p>

<!--more-->

<h2 id="docker-compose">Docker Compose</h2>

<p>Nous allons décrire l’ensemble des services sous la forme d’une application docker compose.
Docker Compose permet de décrire une liste de container Dokcer et leur interdépendance.
Cette configuration est décrite dans un fichier docker-compose.yml qui compose l’application
complète.</p>

<p>Voila le fichier docker-compose.yml de notre application Kafka, Storm &amp; Hadoop:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>docker-compose.yml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
</pre></td><td class="code"><pre><code class="yaml"><span class="line"><span class="l-Scalar-Plain">zookeeper</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/zookeeper</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;2181:2181&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22222:22&quot;</span>
</span><span class="line"><span class="l-Scalar-Plain">hadoop</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">sequenceiq/hadoop-docker:2.7.0</span>
</span><span class="line">  <span class="l-Scalar-Plain">expose</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;9000&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;50010&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="c1"># Ssh</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22227:2122&quot;</span>
</span><span class="line"><span class="l-Scalar-Plain">kafka</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/kafka:0.8.2.0</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;9092:9092&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22223:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">  <span class="l-Scalar-Plain">environment</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="l-Scalar-Plain">KAFKA_ADVERTISED_HOST_NAME</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">192.168.99.100</span>
</span><span class="line">  <span class="l-Scalar-Plain">volumes</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/var/run/docker.sock:/var/run/docker.sock</span>
</span><span class="line"><span class="l-Scalar-Plain">nimbus</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-nimbus</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49773:3773&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49772:3772&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49627:6627&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22224:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">kafka:kf</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hadoop:hp</span>
</span><span class="line"><span class="l-Scalar-Plain">supervisor</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-supervisor</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;8000&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22225:22&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;6703:6703&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">nimbus:nimbus</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">kafka:kf</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hadoop:hp</span>
</span><span class="line"><span class="l-Scalar-Plain">ui</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-ui</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49080:8080&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22226:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">nimbus:nimbus</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Récuperer le repository git docker-kafka-storm-hdfs contenant le fichier docker-compose.yml et les fichiers DockerFile:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">$ </span>git clone https://github.com/Nexys-Technology/docker-kafka-storm-hdfs.git
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>docker-kafka-storm-hdfs
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Avant de démarrer les containers il faut modifier la ligne 42 du fichier docker-compose.yml par l’adresse ip
de la vm docker.</p>

<p>Pour avoir l’adresse IP de la VM docker par défaut utiliser la commande suivante:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-machine ip default
</span><span class="line">192.168.99.100
</span><span class="line">~/docker-kafka-storm-hdfs <span class="err">$</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Démarrer les containers avec docker-compose. Lors du premier lancement docker va récupérer toutes images par téléchargement donc c’est le bon moment pour une pause ;):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-compose up
</span><span class="line">Creating ksh_zookeeper_1...
</span><span class="line">Creating ksh_hadoop_1...
</span><span class="line">Creating ksh_kafka_1...
</span><span class="line">Creating ksh_nimbus_1...
</span><span class="line">Creating ksh_ui_1...
</span><span class="line">Creating ksh_supervisor_1...
</span><span class="line">Attaching to ksh_zookeeper_1, ksh_hadoop_1, ksh_kafka_1, ksh_nimbus_1, ksh_ui_1, ksh_supervisor_1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p class="image-left"><img src="http://nexys-technology.github.io/images/2015-08-13-Docker-Kafka-Storm-HDFS-2/DockerCompose-up.gif" alt="DockerComposeUp" /></p>

<p>Si docker-compose à réussi à démarrer les containers on peux vérifier qu’ils sont bien lancés par la commande suivante:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-compose ps
</span><span class="line">                   Name                                           Command                                          State                                           Ports
</span><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class="line">ksh_hadoop_1                                    /etc/bootstrap.sh -d                            Up                                              19888/tcp, 0.0.0.0:22227-&gt;2122/tcp,
</span><span class="line">                                                                                                                                                49707/tcp, 50010/tcp, 50020/tcp, 50070/tcp,
</span><span class="line">                                                                                                                                                50075/tcp, 50090/tcp, 8030/tcp, 8031/tcp,
</span><span class="line">                                                                                                                                                8032/tcp, 8033/tcp, 8040/tcp, 8042/tcp,
</span><span class="line">                                                                                                                                                8088/tcp, 9000/tcp
</span><span class="line">ksh_kafka_1                                     /bin/sh -c start-kafka.sh                       Up                                              0.0.0.0:22223-&gt;22/tcp, 0.0.0.0:9092-&gt;9092/tcp
</span><span class="line">ksh_nimbus_1                                    /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22224-&gt;22/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49772-&gt;3772/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49773-&gt;3773/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49627-&gt;6627/tcp
</span><span class="line">ksh_supervisor_1                                /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22225-&gt;22/tcp, 6700/tcp, 6701/tcp,
</span><span class="line">                                                                                                                                                6702/tcp, 0.0.0.0:6703-&gt;6703/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:32772-&gt;8000/tcp
</span><span class="line">ksh_ui_1                                        /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22226-&gt;22/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49080-&gt;8080/tcp
</span><span class="line">ksh_zookeeper_1                                 /bin/sh -c /usr/sbin/sshd  ...                  Up                                              0.0.0.0:2181-&gt;2181/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:22222-&gt;22/tcp, 2888/tcp, 3888/tcp
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Dans une autre fenétre terminal démarrer un shell Kafka dans un container avec la commande suivante et créer le topic Kafka:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>./start-kafka-shell.sh <span class="k">$(</span>docker-machine ip default<span class="k">)</span> <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:2181
</span><span class="line">root@09c715741c84:/# <span class="nv">$KAFKA_HOME</span>/bin/kafka-topics.sh --create --topic truckevent --partitions <span class="m">1</span> --zookeeper <span class="nv">$ZK</span> --replication-factor 1
</span><span class="line">Created topic <span class="s2">&quot;truckevent&quot;</span>.
</span><span class="line">root@09c715741c84:/# <span class="nv">$KAFKA_HOME</span>/bin/kafka-topics.sh --describe --topic truckevent --zookeeper <span class="nv">$ZK</span>
</span><span class="line">Topic:truckevent    PartitionCount:1    ReplicationFactor:1 Configs:
</span><span class="line">    Topic: truckevent   Partition: <span class="m">0</span>    Leader: <span class="m">9092</span>    Replicas: <span class="m">9092</span>  Isr: 9092
</span><span class="line">root@09c715741c84:/#
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Transférer le traitement Storm dans le container Nimbus (le mot de passe est <em>wurstmeister</em>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>scp -P <span class="m">22224</span> TruckEvents/Tutorials-master/target/Tutorial-1.0-SNAPSHOT.jar root@<span class="k">$(</span>docker-machine ip default<span class="k">)</span>:/tmp
</span><span class="line">Tutorial-1.0-SNAPSHOT.jar                                                                                                                                      100%  102MB 101.7MB/s   00:01
</span><span class="line">~/docker-kafka-storm-hdfs <span class="err">$</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Entrer dans un shell du container Storm Numbus</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker <span class="nb">exec</span> -it ksh_nimbus_1 /bin/bash
</span><span class="line">root@cd60947fb0aa:/#
</span><span class="line">root@cd60947fb0aa:/# <span class="nb">cd</span> /tmp
</span><span class="line">root@cd60947fb0aa:/tmp# ls -l
</span><span class="line">total 104168
</span><span class="line">-rw-r--r-- <span class="m">1</span> root root <span class="m">106659847</span> Aug <span class="m">14</span> 16:58 Tutorial-1.0-SNAPSHOT.jar
</span><span class="line">drwxr-xr-x <span class="m">2</span> root root      <span class="m">4096</span> Aug <span class="m">14</span> 16:40 hsperfdata_root
</span><span class="line">root@cd60947fb0aa:/tmp# storm jar Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial3.TruckEventProcessingTopology
</span><span class="line">SLF4J: Class path contains multiple SLF4J bindings.
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/tmp/Tutorial-1.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings <span class="k">for</span> an explanation.
</span><span class="line">SLF4J: Actual binding is of <span class="nb">type</span> <span class="o">[</span>ch.qos.logback.classic.util.ContextSelectorStaticBinder<span class="o">]</span>
</span><span class="line">Running: /usr/lib/jvm/java-7-openjdk-amd64/bin/java -client -Dstorm.options<span class="o">=</span> -Dstorm.home<span class="o">=</span>/opt/apache-storm-0.9.4 -Dstorm.log.dir<span class="o">=</span>/opt/apache-storm-0.9.4/logs -Djava.library.path<span class="o">=</span>/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file<span class="o">=</span> -cp /opt/apache-storm-0.9.4/lib/carbonite-1.4.0.jar:/opt/apache-storm-0.9.4/lib/tools.macro-0.1.0.jar:/opt/apache-storm-0.9.4/lib/jetty-6.1.26.jar:/opt/apache-storm-0.9.4/lib/reflectasm-1.07-shaded.jar:/opt/apache-storm-0.9.4/lib/clj-stacktrace-0.2.2.jar:/opt/apache-storm-0.9.4/lib/joda-time-2.0.jar:/opt/apache-storm-0.9.4/lib/objenesis-1.2.jar:/opt/apache-storm-0.9.4/lib/hiccup-0.3.6.jar:/opt/apache-storm-0.9.4/lib/ring-jetty-adapter-0.3.11.jar:/opt/apache-storm-0.9.4/lib/asm-4.0.jar:/opt/apache-storm-0.9.4/lib/tools.cli-0.2.4.jar:/opt/apache-storm-0.9.4/lib/tools.logging-0.2.3.jar:/opt/apache-storm-0.9.4/lib/log4j-over-slf4j-1.6.6.jar:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar:/opt/apache-storm-0.9.4/lib/jgrapht-core-0.9.0.jar:/opt/apache-storm-0.9.4/lib/disruptor-2.10.1.jar:/opt/apache-storm-0.9.4/lib/logback-core-1.0.13.jar:/opt/apache-storm-0.9.4/lib/commons-fileupload-1.2.1.jar:/opt/apache-storm-0.9.4/lib/ring-devel-0.3.11.jar:/opt/apache-storm-0.9.4/lib/compojure-1.1.3.jar:/opt/apache-storm-0.9.4/lib/kryo-2.21.jar:/opt/apache-storm-0.9.4/lib/commons-exec-1.1.jar:/opt/apache-storm-0.9.4/lib/storm-core-0.9.4.jar:/opt/apache-storm-0.9.4/lib/commons-logging-1.1.3.jar:/opt/apache-storm-0.9.4/lib/jline-2.11.jar:/opt/apache-storm-0.9.4/lib/ring-servlet-0.3.11.jar:/opt/apache-storm-0.9.4/lib/core.incubator-0.1.0.jar:/opt/apache-storm-0.9.4/lib/jetty-util-6.1.26.jar:/opt/apache-storm-0.9.4/lib/snakeyaml-1.11.jar:/opt/apache-storm-0.9.4/lib/math.numeric-tower-0.0.1.jar:/opt/apache-storm-0.9.4/lib/slf4j-api-1.7.5.jar:/opt/apache-storm-0.9.4/lib/clj-time-0.4.1.jar:/opt/apache-storm-0.9.4/lib/commons-codec-1.6.jar:/opt/apache-storm-0.9.4/lib/clout-1.0.1.jar:/opt/apache-storm-0.9.4/lib/servlet-api-2.5.jar:/opt/apache-storm-0.9.4/lib/clojure-1.5.1.jar:/opt/apache-storm-0.9.4/lib/commons-lang-2.5.jar:/opt/apache-storm-0.9.4/lib/commons-io-2.4.jar:/opt/apache-storm-0.9.4/lib/json-simple-1.1.jar:/opt/apache-storm-0.9.4/lib/minlog-1.2.jar:/opt/apache-storm-0.9.4/lib/chill-java-0.3.5.jar:/opt/apache-storm-0.9.4/lib/ring-core-1.1.5.jar:Tutorial-1.0-SNAPSHOT.jar:/opt/apache-storm-0.9.4/conf:/opt/apache-storm-0.9.4/bin -Dstorm.jar<span class="o">=</span>Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial3.TruckEventProcessingTopology
</span><span class="line">SLF4J: Class path contains multiple SLF4J bindings.
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/tmp/Tutorial-1.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings <span class="k">for</span> an explanation.
</span><span class="line">SLF4J: Actual binding is of <span class="nb">type</span> <span class="o">[</span>ch.qos.logback.classic.util.ContextSelectorStaticBinder<span class="o">]</span>
</span><span class="line"><span class="m">835</span>  <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Jar not uploaded to master yet. Submitting jar...
</span><span class="line"><span class="m">846</span>  <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Uploading topology jar Tutorial-1.0-SNAPSHOT.jar to assigned location: storm-local/nimbus/inbox/stormjar-d1a5a232-ca72-44b1-a0de-34a7b28e73e8.jar
</span><span class="line"><span class="m">1351</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Successfully uploaded topology jar to assigned location: storm-local/nimbus/inbox/stormjar-d1a5a232-ca72-44b1-a0de-34a7b28e73e8.jar
</span><span class="line"><span class="m">1351</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Submitting topology truck-event-processor in distributed mode with conf <span class="o">{</span><span class="s2">&quot;topology.debug&quot;</span>:true<span class="o">}</span>
</span><span class="line"><span class="m">2379</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Finished submitting topology: truck-event-processor
</span><span class="line">root@cd60947fb0aa:/tmp#
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ouvrir Storm UI dans un navigateur Web:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>open http://192.168.99.100:49080
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Nous devons avoir une topology visible <em>truck-event-processor</em>. Elle ne doit pas avoir d’erreur (cliquer sur lien
pour avoir le détail de la topology dans l’UI).</p>

<p>Maintenant nous allons générer des messages Kafka:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>java -cp TruckEvents/Tutorials-master/target/Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial1.TruckEventsProducer <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:9092 <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:2181
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Verifying properties
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property metadata.broker.list is overridden to 192.168.99.100:9092
</span><span class="line">15/08/14 19:07:20 WARN utils.VerifiableProperties: Property zk.connect is not valid
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property request.required.acks is overridden to 1
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property serializer.class is overridden to kafka.serializer.StringEncoder
</span><span class="line">1
</span><span class="line">1
</span><span class="line">1
</span><span class="line">1
</span><span class="line">15/08/14 19:07:20 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17: 0, msg:2015-08-14 19:07:20.962|1|11|Normal|-79.762351999999964|42.131190999999944</span>
</span><span class="line">15/08/14 19:07:21 INFO client.ClientUtils<span class="nv">$:</span> Fetching metadata from broker id:0,host:192.168.99.100,port:9092 with correlation id <span class="m">0</span> <span class="k">for</span> <span class="m">1</span> topic<span class="o">(</span>s<span class="o">)</span> Set<span class="o">(</span>truckevent<span class="o">)</span>
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Connected to 192.168.99.100:9092 <span class="k">for</span> producing
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Disconnecting from 192.168.99.100:9092
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Connected to 192.168.99.100:9092 <span class="k">for</span> producing
</span><span class="line">15/08/14 19:07:22 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17k: 0, msg:2015-08-14 19:07:22.194|2|12|Normal|-74.021358|41.500703</span>
</span><span class="line">15/08/14 19:07:23 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route208: 0, msg:2015-08-14 19:07:23.201|3|13|Normal|-74.192248999999947|41.333772999999915</span>
</span><span class="line">15/08/14 19:07:24 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route27: 0, msg:2015-08-14 19:07:24.207|4|14|Lane Departure|-73.995427999999947|40.667374000000109</span>
</span><span class="line">15/08/14 19:07:25 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17: 1, msg:2015-08-14 19:07:25.215|1|11|Normal|-79.74982399999999|42.129476999999952</span>
</span><span class="line">15/08/14 19:07:26 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17k: 1, msg:2015-08-14 19:07:26.222|2|12|Lane Departure|-74.021477|41.500715</span>
</span><span class="line">15/08/14 19:07:27 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route208: 1, msg:2015-08-14 19:07:27.227|3|13|Normal|-74.190990000000056|41.335225999999</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>La vérifions que nous des fichiers dans la partie HDFS:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker <span class="nb">exec</span> -it ksh_hadoop_1 /bin/bash
</span><span class="line">bash-4.1# <span class="nb">cd</span> <span class="nv">$HADOOP_PREFIX</span>
</span><span class="line">bash-4.1# bin/hdfs dfs -ls /truck-events-v4/staging
</span><span class="line">Found <span class="m">4</span> items
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup         <span class="m">57</span> 2015-08-14 13:07 /truck-events-v4/staging/truckEventshdfsBolt-2-0-1439571724879.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup          <span class="m">0</span> 2015-08-14 13:08 /truck-events-v4/staging/truckEventshdfsBolt-2-1-1439572042257.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup         <span class="m">75</span> 2015-08-14 13:07 /truck-events-v4/staging/truckEventshdfsBolt-3-0-1439571724873.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup          <span class="m">0</span> 2015-08-14 13:08 /truck-events-v4/staging/truckEventshdfsBolt-3-1-1439572041979.txt
</span><span class="line">bash-4.1# bin/hdfs dfs -cat truck-events-v4/staging/truckEventshdfsBolt-2-0-1439571724879.txt
</span><span class="line">12,2,2015-08-14 19:07:22.194,Normal,-74.021358,41.500703
</span><span class="line">bash-4.1#
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Docker, Kafka, Storm et Hadoop HDFS 1er partie]]></title>
        <link href="http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-1/"/>
        <updated>2015-08-12T00:00:00+02:00</updated>
        <id>http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-1</id>
        <content type="html"><![CDATA[<p>Le but de cette suite de posts est de décrire l’installation d’un environnement fonctionnel
 de Kafka, Storm &amp; Hadoop avec docker.
Nous utiliserons la version 1.8 de docker avec graylog 2 pour la centralisation des logs entre les containers.
Après l’installation de cette environnement nous déployeront un traitement storm pour consommer 
des messages Kafka et les écrires dans des fichiers stockés sur le filesystem HDFS.</p>

<!--more-->

<h2 id="initialisation-de-lenvironnement-docker">Initialisation de l’environnement Docker</h2>

<ul>
  <li>Télécharger DockerToolbox: <a href="https://www.docker.com/toolbox">DockerToolbox</a></li>
  <li>Installer l’application en executer le programme d’installation</li>
  <li>Lancer le shell Docker Quickstart Terminal ou dans le cas d’un shell existant</li>
  <li>ou lancer la commande suivante dans un shell existant pour initialiser les variables d’nevironnements docker: <code>eval $(docker-machine env default --shell=zsh)</code> (changer le zsh en bash en fonction de votre shell)</li>
</ul>

<p>Vérifier que docker fonctionne correctement:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">$ </span>docker version
</span><span class="line">Client:
</span><span class="line"> Version:      1.8.0
</span><span class="line"> API version:  1.20
</span><span class="line"> Go version:   go1.4.2
</span><span class="line"> Git commit:   0d03096
</span><span class="line"> Built:        Tue Aug <span class="m">11</span> 17:17:40 UTC 2015
</span><span class="line"> OS/Arch:      darwin/amd64
</span><span class="line">
</span><span class="line">Server:
</span><span class="line"> Version:      1.8.0
</span><span class="line"> API version:  1.20
</span><span class="line"> Go version:   go1.4.2
</span><span class="line"> Git commit:   0d03096
</span><span class="line"> Built:        Tue Aug <span class="m">11</span> 17:17:40 UTC 2015
</span><span class="line"> OS/Arch:      linux/amd64
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="cration-dun-machine-virtuel-avec-docker-machine">Création d’un machine virtuel avec docker-machine</h2>

<p>Nous allons récréer la VM default avece 4G de Ram et 60Gb de disque:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">$ </span>docker-machine stop default
</span><span class="line"><span class="nv">$ </span>docker-machine rm default
</span><span class="line"><span class="nv">$ </span>docker-machine create -d virtualbox --virtualbox-memory <span class="m">4096</span> --virtualbox-disk-size <span class="m">60000</span> default
</span><span class="line"><span class="nv">$ </span><span class="nb">eval</span> <span class="k">$(</span><span class="nv">$DOCKER_MACHINE</span> env default --shell<span class="o">=</span>zsh<span class="k">)</span>
</span><span class="line"><span class="nv">$ </span>docker-machine ls
</span><span class="line">NAME      ACTIVE   DRIVER       STATE     URL                         SWARM
</span><span class="line">default   *        virtualbox   Running   tcp://192.168.99.101:2376
</span><span class="line"><span class="err">$</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="cration-du-container-graylog-pour-centraliser-les-logs">Création du container Graylog pour centraliser les logs</h2>

<p>Nous allons utiliser Graylog 2 pour centraliser les logs des difféerents containers.
Utilisons le container standard pour déployer un système Graylog 2 complet:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">$ </span>docker run -t -p 19000:9000 -p 12201:12201/udp graylog2/allinone
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Se connecter à l’interface GrayLog 2: <code>open http://$(docker-machine ip default):19000</code></p>

<p>Aller dnas le menu  System/input et créer un input de type GELF UDP donner lui un nom (ex: Docker Log). Ensuite essayons un container avec la redirection des logs vers GrayLog:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">docker run --log-driver<span class="o">=</span>gelf --log-opt gelf-address<span class="o">=</span>udp://<span class="k">$(</span>docker-machine ip default<span class="k">)</span>:12201 busybox <span class="nb">echo </span>Hello Graylog
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Vour devriez avoir un nouveau message dans GrayLog:</p>

<p class="image-left"><img src="http://nexys-technology.github.io/images/messages.png" alt="GrayLog Message" /></p>

<p>Voila pour cette première partie. Dans la suivante nous verrons comment déployer les containers Kafka, Storm et Hadoop</p>

]]></content>
    </entry>
    
</feed>
