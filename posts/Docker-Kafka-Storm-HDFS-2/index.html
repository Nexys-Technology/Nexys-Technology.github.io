<!doctype html>
    <!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
    <!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
    <!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
    <!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

    
      
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Docker, Kafka, Storm et Hadoop HDFS 2éme partie - Nexys Technology</title>
        <meta name="author" content="Nexys Consulting">
        
        <meta name="description" content="Création d'un environnement Kafka, Storm & Hadoop avec Docker 2: Création des containers">
        
        <meta name="viewport" content="width=device-width">
        <link rel="canonical" href="http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-2">

        <link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,400italic' rel='stylesheet' type='text/css'>
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        
        <link href="/favicon.png" rel="icon">
        <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet">
        <link href="/atom.xml" rel="alternate" title="Nexys Technology" type="application/atom+xml">
    </head>


    <body >

        <header id="header">
    <div class="row">
    <div class="col-xs-12 col-sm-8 col-md-4">
        <a href="/" class="site-title">Nexys Technology</a>
    </div>
    <div class="col-xs-12 col-sm-4 col-md-8">
        <nav>
    <input type="checkbox" id="toggle">
    <label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu"></label>
    <ul class="menu">
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
</ul>

</nav>

    </div>
</div>

</header>


        <div id="main-content">

            <!--[if lte IE 9]>
<div class="row upgrade-row">
    <div class="col-lg-12">
        <div class="upgrade">
            <i class="upgrade__icon fa fa-warning"></i>
            <h1 class="upgrade__title h6">Ohnoes!</h1>
            <p class="upgrade__text">
                Unfortunately, certain parts of this site may not display correctly in your version of Internet Explorer!<br>
                If possible, you should consider <a href="http://browsehappy.com/">upgrading your browser</a>.
            </p>
        </div>
    </div>
</div>
<!-- <![endif]-->


            

            <div class="row top-xs center-sm center-md center-lg site-wrapper">
                
                <div class="col-xs-12 col-sm-10 col-md-8 col-lg-8">
                
                    <article class="article article--single">
    <header class="article__header">
    
        <h1 class="article__title">Docker, Kafka, Storm et Hadoop HDFS 2éme partie</h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2015-08-13T00:00:00+02:00" pubdate><i class="fa fa-calendar"></i> 2015-08-13</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        

            
                <li><a class='category' href='/blog/categories/hadoop/'>hadoop</a></li>
            
                <li><a class='category' href='/blog/categories/docker/'>docker</a></li>
            
                <li><a class='category' href='/blog/categories/kafka/'>kafka</a></li>
            
                <li><a class='category' href='/blog/categories/storm/'>storm</a></li>
            
        
        </ul>
    </div>


            
                <a class="pull-right" href="#disqus_thread">
                    Commentaires <i class="fa fa-comment"></i>
                </a>
            
        </div>
    
</header>




    <p>Dans cette partie nous allons déployer les containers dockers pour Kafka, Storm
et Hadoop avec l’aide de docker-compose.</p>

<!--more-->

<h2 id="docker-compose">Docker Compose</h2>

<p>Nous allons décrire l’ensemble des services sous la forme d’une application docker compose.
Docker Compose permet de décrire une liste de container Dokcer et leur interdépendance.
Cette configuration est décrite dans un fichier docker-compose.yml qui compose l’application
complète.</p>

<p>Voila le fichier docker-compose.yml de notre application Kafka, Storm &amp; Hadoop:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>docker-compose.yml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
</pre></td><td class="code"><pre><code class="yaml"><span class="line"><span class="l-Scalar-Plain">zookeeper</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/zookeeper</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;2181:2181&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22222:22&quot;</span>
</span><span class="line"><span class="l-Scalar-Plain">hadoop</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">sequenceiq/hadoop-docker:2.7.0</span>
</span><span class="line">  <span class="l-Scalar-Plain">expose</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;9000&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;50010&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="c1"># Ssh</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22227:2122&quot;</span>
</span><span class="line"><span class="l-Scalar-Plain">kafka</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/kafka:0.8.2.0</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;9092:9092&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22223:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">  <span class="l-Scalar-Plain">environment</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="l-Scalar-Plain">KAFKA_ADVERTISED_HOST_NAME</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">192.168.99.100</span>
</span><span class="line">  <span class="l-Scalar-Plain">volumes</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/var/run/docker.sock:/var/run/docker.sock</span>
</span><span class="line"><span class="l-Scalar-Plain">nimbus</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-nimbus</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49773:3773&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49772:3772&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49627:6627&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22224:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">kafka:kf</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hadoop:hp</span>
</span><span class="line"><span class="l-Scalar-Plain">supervisor</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-supervisor</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;8000&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22225:22&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;6703:6703&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">nimbus:nimbus</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">kafka:kf</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">hadoop:hp</span>
</span><span class="line"><span class="l-Scalar-Plain">ui</span><span class="p-Indicator">:</span>
</span><span class="line">  <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">wurstmeister/storm-ui</span>
</span><span class="line">  <span class="l-Scalar-Plain">ports</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;49080:8080&quot;</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="s">&quot;22226:22&quot;</span>
</span><span class="line">  <span class="l-Scalar-Plain">links</span><span class="p-Indicator">:</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">nimbus:nimbus</span>
</span><span class="line">    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">zookeeper:zk</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Récuperer le repository git docker-kafka-storm-hdfs contenant le fichier docker-compose.yml et les fichiers DockerFile:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nv">$ </span>git clone https://github.com/Nexys-Technology/docker-kafka-storm-hdfs.git
</span><span class="line"><span class="nv">$ </span><span class="nb">cd </span>docker-kafka-storm-hdfs
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Avant de démarrer les containers il faut modifier la ligne 42 du fichier docker-compose.yml par l’adresse ip
de la vm docker.</p>

<p>Pour avoir l’adresse IP de la VM docker par défaut utiliser la commande suivante:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-machine ip default
</span><span class="line">192.168.99.100
</span><span class="line">~/docker-kafka-storm-hdfs <span class="err">$</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Démarrer les containers avec docker-compose. Lors du premier lancement docker va récupérer toutes images par téléchargement donc c’est le bon moment pour une pause ;):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-compose up
</span><span class="line">Creating ksh_zookeeper_1...
</span><span class="line">Creating ksh_hadoop_1...
</span><span class="line">Creating ksh_kafka_1...
</span><span class="line">Creating ksh_nimbus_1...
</span><span class="line">Creating ksh_ui_1...
</span><span class="line">Creating ksh_supervisor_1...
</span><span class="line">Attaching to ksh_zookeeper_1, ksh_hadoop_1, ksh_kafka_1, ksh_nimbus_1, ksh_ui_1, ksh_supervisor_1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p class="image-left"><img src="http://nexys-technology.github.io/images/2015-08-13-Docker-Kafka-Storm-HDFS-2/DockerCompose-up.gif" alt="DockerComposeUp" /></p>

<p>Si docker-compose à réussi à démarrer les containers on peux vérifier qu’ils sont bien lancés par la commande suivante:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker-compose ps
</span><span class="line">                   Name                                           Command                                          State                                           Ports
</span><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span><span class="line">ksh_hadoop_1                                    /etc/bootstrap.sh -d                            Up                                              19888/tcp, 0.0.0.0:22227-&gt;2122/tcp,
</span><span class="line">                                                                                                                                                49707/tcp, 50010/tcp, 50020/tcp, 50070/tcp,
</span><span class="line">                                                                                                                                                50075/tcp, 50090/tcp, 8030/tcp, 8031/tcp,
</span><span class="line">                                                                                                                                                8032/tcp, 8033/tcp, 8040/tcp, 8042/tcp,
</span><span class="line">                                                                                                                                                8088/tcp, 9000/tcp
</span><span class="line">ksh_kafka_1                                     /bin/sh -c start-kafka.sh                       Up                                              0.0.0.0:22223-&gt;22/tcp, 0.0.0.0:9092-&gt;9092/tcp
</span><span class="line">ksh_nimbus_1                                    /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22224-&gt;22/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49772-&gt;3772/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49773-&gt;3773/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49627-&gt;6627/tcp
</span><span class="line">ksh_supervisor_1                                /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22225-&gt;22/tcp, 6700/tcp, 6701/tcp,
</span><span class="line">                                                                                                                                                6702/tcp, 0.0.0.0:6703-&gt;6703/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:32772-&gt;8000/tcp
</span><span class="line">ksh_ui_1                                        /bin/sh -c /usr/bin/start- ...                  Up                                              0.0.0.0:22226-&gt;22/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:49080-&gt;8080/tcp
</span><span class="line">ksh_zookeeper_1                                 /bin/sh -c /usr/sbin/sshd  ...                  Up                                              0.0.0.0:2181-&gt;2181/tcp,
</span><span class="line">                                                                                                                                                0.0.0.0:22222-&gt;22/tcp, 2888/tcp, 3888/tcp
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Dans une autre fenétre terminal démarrer un shell Kafka dans un container avec la commande suivante et créer le topic Kafka:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>./start-kafka-shell.sh <span class="k">$(</span>docker-machine ip default<span class="k">)</span> <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:2181
</span><span class="line">root@09c715741c84:/# <span class="nv">$KAFKA_HOME</span>/bin/kafka-topics.sh --create --topic truckevent --partitions <span class="m">1</span> --zookeeper <span class="nv">$ZK</span> --replication-factor 1
</span><span class="line">Created topic <span class="s2">&quot;truckevent&quot;</span>.
</span><span class="line">root@09c715741c84:/# <span class="nv">$KAFKA_HOME</span>/bin/kafka-topics.sh --describe --topic truckevent --zookeeper <span class="nv">$ZK</span>
</span><span class="line">Topic:truckevent    PartitionCount:1    ReplicationFactor:1 Configs:
</span><span class="line">    Topic: truckevent   Partition: <span class="m">0</span>    Leader: <span class="m">9092</span>    Replicas: <span class="m">9092</span>  Isr: 9092
</span><span class="line">root@09c715741c84:/#
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Transférer le traitement Storm dans le container Nimbus (le mot de passe est <em>wurstmeister</em>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>scp -P <span class="m">22224</span> TruckEvents/Tutorials-master/target/Tutorial-1.0-SNAPSHOT.jar root@<span class="k">$(</span>docker-machine ip default<span class="k">)</span>:/tmp
</span><span class="line">Tutorial-1.0-SNAPSHOT.jar                                                                                                                                      100%  102MB 101.7MB/s   00:01
</span><span class="line">~/docker-kafka-storm-hdfs <span class="err">$</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Entrer dans un shell du container Storm Numbus</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker <span class="nb">exec</span> -it ksh_nimbus_1 /bin/bash
</span><span class="line">root@cd60947fb0aa:/#
</span><span class="line">root@cd60947fb0aa:/# <span class="nb">cd</span> /tmp
</span><span class="line">root@cd60947fb0aa:/tmp# ls -l
</span><span class="line">total 104168
</span><span class="line">-rw-r--r-- <span class="m">1</span> root root <span class="m">106659847</span> Aug <span class="m">14</span> 16:58 Tutorial-1.0-SNAPSHOT.jar
</span><span class="line">drwxr-xr-x <span class="m">2</span> root root      <span class="m">4096</span> Aug <span class="m">14</span> 16:40 hsperfdata_root
</span><span class="line">root@cd60947fb0aa:/tmp# storm jar Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial3.TruckEventProcessingTopology
</span><span class="line">SLF4J: Class path contains multiple SLF4J bindings.
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/tmp/Tutorial-1.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings <span class="k">for</span> an explanation.
</span><span class="line">SLF4J: Actual binding is of <span class="nb">type</span> <span class="o">[</span>ch.qos.logback.classic.util.ContextSelectorStaticBinder<span class="o">]</span>
</span><span class="line">Running: /usr/lib/jvm/java-7-openjdk-amd64/bin/java -client -Dstorm.options<span class="o">=</span> -Dstorm.home<span class="o">=</span>/opt/apache-storm-0.9.4 -Dstorm.log.dir<span class="o">=</span>/opt/apache-storm-0.9.4/logs -Djava.library.path<span class="o">=</span>/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file<span class="o">=</span> -cp /opt/apache-storm-0.9.4/lib/carbonite-1.4.0.jar:/opt/apache-storm-0.9.4/lib/tools.macro-0.1.0.jar:/opt/apache-storm-0.9.4/lib/jetty-6.1.26.jar:/opt/apache-storm-0.9.4/lib/reflectasm-1.07-shaded.jar:/opt/apache-storm-0.9.4/lib/clj-stacktrace-0.2.2.jar:/opt/apache-storm-0.9.4/lib/joda-time-2.0.jar:/opt/apache-storm-0.9.4/lib/objenesis-1.2.jar:/opt/apache-storm-0.9.4/lib/hiccup-0.3.6.jar:/opt/apache-storm-0.9.4/lib/ring-jetty-adapter-0.3.11.jar:/opt/apache-storm-0.9.4/lib/asm-4.0.jar:/opt/apache-storm-0.9.4/lib/tools.cli-0.2.4.jar:/opt/apache-storm-0.9.4/lib/tools.logging-0.2.3.jar:/opt/apache-storm-0.9.4/lib/log4j-over-slf4j-1.6.6.jar:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar:/opt/apache-storm-0.9.4/lib/jgrapht-core-0.9.0.jar:/opt/apache-storm-0.9.4/lib/disruptor-2.10.1.jar:/opt/apache-storm-0.9.4/lib/logback-core-1.0.13.jar:/opt/apache-storm-0.9.4/lib/commons-fileupload-1.2.1.jar:/opt/apache-storm-0.9.4/lib/ring-devel-0.3.11.jar:/opt/apache-storm-0.9.4/lib/compojure-1.1.3.jar:/opt/apache-storm-0.9.4/lib/kryo-2.21.jar:/opt/apache-storm-0.9.4/lib/commons-exec-1.1.jar:/opt/apache-storm-0.9.4/lib/storm-core-0.9.4.jar:/opt/apache-storm-0.9.4/lib/commons-logging-1.1.3.jar:/opt/apache-storm-0.9.4/lib/jline-2.11.jar:/opt/apache-storm-0.9.4/lib/ring-servlet-0.3.11.jar:/opt/apache-storm-0.9.4/lib/core.incubator-0.1.0.jar:/opt/apache-storm-0.9.4/lib/jetty-util-6.1.26.jar:/opt/apache-storm-0.9.4/lib/snakeyaml-1.11.jar:/opt/apache-storm-0.9.4/lib/math.numeric-tower-0.0.1.jar:/opt/apache-storm-0.9.4/lib/slf4j-api-1.7.5.jar:/opt/apache-storm-0.9.4/lib/clj-time-0.4.1.jar:/opt/apache-storm-0.9.4/lib/commons-codec-1.6.jar:/opt/apache-storm-0.9.4/lib/clout-1.0.1.jar:/opt/apache-storm-0.9.4/lib/servlet-api-2.5.jar:/opt/apache-storm-0.9.4/lib/clojure-1.5.1.jar:/opt/apache-storm-0.9.4/lib/commons-lang-2.5.jar:/opt/apache-storm-0.9.4/lib/commons-io-2.4.jar:/opt/apache-storm-0.9.4/lib/json-simple-1.1.jar:/opt/apache-storm-0.9.4/lib/minlog-1.2.jar:/opt/apache-storm-0.9.4/lib/chill-java-0.3.5.jar:/opt/apache-storm-0.9.4/lib/ring-core-1.1.5.jar:Tutorial-1.0-SNAPSHOT.jar:/opt/apache-storm-0.9.4/conf:/opt/apache-storm-0.9.4/bin -Dstorm.jar<span class="o">=</span>Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial3.TruckEventProcessingTopology
</span><span class="line">SLF4J: Class path contains multiple SLF4J bindings.
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/opt/apache-storm-0.9.4/lib/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: Found binding in <span class="o">[</span>jar:file:/tmp/Tutorial-1.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class<span class="o">]</span>
</span><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings <span class="k">for</span> an explanation.
</span><span class="line">SLF4J: Actual binding is of <span class="nb">type</span> <span class="o">[</span>ch.qos.logback.classic.util.ContextSelectorStaticBinder<span class="o">]</span>
</span><span class="line"><span class="m">835</span>  <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Jar not uploaded to master yet. Submitting jar...
</span><span class="line"><span class="m">846</span>  <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Uploading topology jar Tutorial-1.0-SNAPSHOT.jar to assigned location: storm-local/nimbus/inbox/stormjar-d1a5a232-ca72-44b1-a0de-34a7b28e73e8.jar
</span><span class="line"><span class="m">1351</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Successfully uploaded topology jar to assigned location: storm-local/nimbus/inbox/stormjar-d1a5a232-ca72-44b1-a0de-34a7b28e73e8.jar
</span><span class="line"><span class="m">1351</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Submitting topology truck-event-processor in distributed mode with conf <span class="o">{</span><span class="s2">&quot;topology.debug&quot;</span>:true<span class="o">}</span>
</span><span class="line"><span class="m">2379</span> <span class="o">[</span>main<span class="o">]</span> INFO  backtype.storm.StormSubmitter - Finished submitting topology: truck-event-processor
</span><span class="line">root@cd60947fb0aa:/tmp#
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ouvrir Storm UI dans un navigateur Web:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>open http://192.168.99.100:49080
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Nous devons avoir une topology visible <em>truck-event-processor</em>. Elle ne doit pas avoir d’erreur (cliquer sur lien
pour avoir le détail de la topology dans l’UI).</p>

<p>Maintenant nous allons générer des messages Kafka:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>java -cp TruckEvents/Tutorials-master/target/Tutorial-1.0-SNAPSHOT.jar com.hortonworks.tutorials.tutorial1.TruckEventsProducer <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:9092 <span class="k">$(</span>docker-machine ip default<span class="k">)</span>:2181
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Verifying properties
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property metadata.broker.list is overridden to 192.168.99.100:9092
</span><span class="line">15/08/14 19:07:20 WARN utils.VerifiableProperties: Property zk.connect is not valid
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property request.required.acks is overridden to 1
</span><span class="line">15/08/14 19:07:20 INFO utils.VerifiableProperties: Property serializer.class is overridden to kafka.serializer.StringEncoder
</span><span class="line">1
</span><span class="line">1
</span><span class="line">1
</span><span class="line">1
</span><span class="line">15/08/14 19:07:20 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17: 0, msg:2015-08-14 19:07:20.962|1|11|Normal|-79.762351999999964|42.131190999999944</span>
</span><span class="line">15/08/14 19:07:21 INFO client.ClientUtils<span class="nv">$:</span> Fetching metadata from broker id:0,host:192.168.99.100,port:9092 with correlation id <span class="m">0</span> <span class="k">for</span> <span class="m">1</span> topic<span class="o">(</span>s<span class="o">)</span> Set<span class="o">(</span>truckevent<span class="o">)</span>
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Connected to 192.168.99.100:9092 <span class="k">for</span> producing
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Disconnecting from 192.168.99.100:9092
</span><span class="line">15/08/14 19:07:21 INFO producer.SyncProducer: Connected to 192.168.99.100:9092 <span class="k">for</span> producing
</span><span class="line">15/08/14 19:07:22 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17k: 0, msg:2015-08-14 19:07:22.194|2|12|Normal|-74.021358|41.500703</span>
</span><span class="line">15/08/14 19:07:23 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route208: 0, msg:2015-08-14 19:07:23.201|3|13|Normal|-74.192248999999947|41.333772999999915</span>
</span><span class="line">15/08/14 19:07:24 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route27: 0, msg:2015-08-14 19:07:24.207|4|14|Lane Departure|-73.995427999999947|40.667374000000109</span>
</span><span class="line">15/08/14 19:07:25 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17: 1, msg:2015-08-14 19:07:25.215|1|11|Normal|-79.74982399999999|42.129476999999952</span>
</span><span class="line">15/08/14 19:07:26 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route17k: 1, msg:2015-08-14 19:07:26.222|2|12|Lane Departure|-74.021477|41.500715</span>
</span><span class="line">15/08/14 19:07:27 INFO tutorial1.TruckEventsProducer: Sending Messge <span class="c">#: route208: 1, msg:2015-08-14 19:07:27.227|3|13|Normal|-74.190990000000056|41.335225999999</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>La vérifions que nous des fichiers dans la partie HDFS:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">~/docker-kafka-storm-hdfs <span class="nv">$ </span>docker <span class="nb">exec</span> -it ksh_hadoop_1 /bin/bash
</span><span class="line">bash-4.1# <span class="nb">cd</span> <span class="nv">$HADOOP_PREFIX</span>
</span><span class="line">bash-4.1# bin/hdfs dfs -ls /truck-events-v4/staging
</span><span class="line">Found <span class="m">4</span> items
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup         <span class="m">57</span> 2015-08-14 13:07 /truck-events-v4/staging/truckEventshdfsBolt-2-0-1439571724879.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup          <span class="m">0</span> 2015-08-14 13:08 /truck-events-v4/staging/truckEventshdfsBolt-2-1-1439572042257.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup         <span class="m">75</span> 2015-08-14 13:07 /truck-events-v4/staging/truckEventshdfsBolt-3-0-1439571724873.txt
</span><span class="line">-rw-r--r--   <span class="m">3</span> root supergroup          <span class="m">0</span> 2015-08-14 13:08 /truck-events-v4/staging/truckEventshdfsBolt-3-1-1439572041979.txt
</span><span class="line">bash-4.1# bin/hdfs dfs -cat truck-events-v4/staging/truckEventshdfsBolt-2-0-1439571724879.txt
</span><span class="line">12,2,2015-08-14 19:07:22.194,Normal,-74.021358,41.500703
</span><span class="line">bash-4.1#
</span></code></pre></td></tr></table></div></figure></notextile></div>



</article>


<section id="disqus">
    <h1 class="disqus__title">Commentaires</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>


                </div>

                
                <aside class="sidebar col-xs-12 col-md-4 col-lg-4">
                    <div class="row">

    

    


    <section id="recent-posts" class="col-xs-12 col-sm-6 col-md-12">
    <h1>Recent Posts</h1>
    <ul class="divided">
        
        <li class="post">
            <a href="/posts/Docker-Kafka-Storm-HDFS-2/">Docker, Kafka, Storm et Hadoop HDFS 2éme partie</a>
        </li>
        
        <li class="post">
            <a href="/posts/Docker-Kafka-Storm-HDFS-1/">Docker, Kafka, Storm et Hadoop HDFS 1er partie</a>
        </li>
        
    </ul>
</section>






</div>

                </aside>
                
            </div>
        </div>

        

    
    




<footer class="footer">
    <div class="row middle-xs">
        
        <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
            <p class="footer__copyright">
    All content copyright Nexys Consulting.<br>
    Code under <a href="//github.com/coogie/oscailte/blob/master/README.md">MIT Licence</a>.
</p>

        </div>
        
        
    </div>
</footer>


        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
<script src="//crypto-js.googlecode.com/svn/tags/3.1.2/build/rollups/md5.js"></script>
<script defer src="/javascripts/octopress.js"></script>


<script>
    var _gaq=[['_setAccount','UA-44848227-6'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>



<script>
    var disqus_shortname = 'nexystechnology';
    
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-2/';
        var disqus_url = 'http://nexys-technology.github.io/posts/Docker-Kafka-Storm-HDFS-2/';
        var disqus_script = 'embed.js';
    
    (function () {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











    </body>

</html>
